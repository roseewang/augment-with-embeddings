{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "import tiktoken\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(filename):\n",
    "    f = io.open(filename, mode=\"r\", encoding=\"utf-8\")\n",
    "    html_doc = f.read()\n",
    "    f.close()\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = extract_text(\"apikey.txt\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunking(text, max_token_count):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    words = text.split()\n",
    "    chunk = []\n",
    "    encodeStr = \"\"\n",
    "    token_count = 0\n",
    "    \n",
    "    \n",
    "    for word in words:\n",
    "        if token_count+len(enc.encode(word))>max_token_count:\n",
    "            chunk.append(encodeStr.strip())\n",
    "            encodeStr = \"\"\n",
    "            token_count = 0\n",
    "        else:\n",
    "            encodeStr = encodeStr + \" \" + word\n",
    "            token_count += len(enc.encode(word))\n",
    "    \n",
    "    if encodeStr:        \n",
    "        chunk.append(encodeStr.strip())\n",
    "        \n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_chunk_text(directory, max_token_count):\n",
    "    results = {}\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.html'):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                text = extract_text(file_path)\n",
    "                chunks = chunking(text, max_tokens)\n",
    "                results[file_path] = chunks\n",
    "                \n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embeddings_of_chunk_batch(batch_chunk,EMBEDDING_MODEL):\n",
    "    print(\"Calculating embedding for batch #\", x)\n",
    "    response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=batch_chunk,\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    for i, embedding in enumerate(response[\"data\"]):\n",
    "        assert i == embedding[\"index\"]\n",
    "\n",
    "    return [e[\"embedding\"] for e in response[\"data\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embeddings_for_dict(chunks_dict):\n",
    "    \"\"\"\n",
    "    Calculate embeddings for a dictionary where each key is a file path and the corresponding value is a list of text chunks.\n",
    "    \n",
    "    Parameters:\n",
    "    - chunks_dict (dict): Dictionary with file paths as keys and lists of text chunks as values.\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with file paths as keys and lists of embeddings as values.\n",
    "    \"\"\"\n",
    "\n",
    "    EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "    BATCH_SIZE = 20000\n",
    "    results = {}\n",
    "    \n",
    "    for path, chunks in chunks_dict.items():\n",
    "        embeddings = []\n",
    "        for x in range(BATCH_SIZE):\n",
    "            start = x * BATCH_SIZE\n",
    "            end = start + BATCH_SIZE\n",
    "            batch = chunks[start:end]\n",
    "\n",
    "            embeddings.extend(calculate_embeddings_of_chunk_batch(batch,EMBEDDING_MODEL))\n",
    "            \n",
    "        results[path] = embeddings\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_for_chunks(chunks):\n",
    "    \"\"\"\n",
    "    Calculate embeddings for a list of text chunks.\n",
    "    \n",
    "    Parameters:\n",
    "    - chunks (list): List of text chunks.\n",
    "    \n",
    "    Returns:\n",
    "    - List of embeddings for each chunk.\n",
    "    \"\"\"\n",
    "\n",
    "    EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "    BATCH_SIZE = 20000\n",
    "    results = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        embeddings = []\n",
    "        for x in range(0,len(chunks),BATCH_SIZE):\n",
    "            start = x\n",
    "            end = start + BATCH_SIZE\n",
    "            batch = chunk[start:end]\n",
    "\n",
    "            embeddings.extend(calculate_embeddings_of_chunk_batch(batch,EMBEDDING_MODEL))\n",
    "        results.append(embeddings)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory_and_get_embeddings(directory, max_tokens=4096):\n",
    "    all_chunks = []\n",
    "    file_paths = []\n",
    "    \n",
    "    file_paths = [file for dirs in os.walk(directory, topdown=True)\n",
    "                     for file in dirs[2] if file.endswith(\".html\")]\n",
    "    \n",
    "    for file in file_paths:\n",
    "        text = extract_text(file)\n",
    "        chunks = chunking(text, max_tokens)\n",
    "        all_chunks.extend(chunks)\n",
    "    \n",
    "    embeddings = get_embeddings_for_chunks(all_chunks)\n",
    "    \n",
    "    return pd.DataFrame({'file_path':file_path, 'text':all_chunks, 'embeddings': embeddings})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}